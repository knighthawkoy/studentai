Portkey
https://github.com/portkey-ai/gateway
https://docs.llamaindex.ai/en/latest/examples/llm/portkey.html


Portkey is a full-stack LLMOps platform that productionizes your Gen AI app reliably and securely.

🚪 AI Gateway:

Automated Fallbacks & Retries: Ensure your application remains functional even if a primary service fails.

Load Balancing: Efficiently distribute incoming requests among multiple models.

Semantic Caching: Reduce costs and latency by intelligently caching results.

🔬 Observability:

Logging: Keep track of all requests for monitoring and debugging.

Requests Tracing: Understand the journey of each request for optimization.

Custom Tags: Segment and categorize requests for better insights.

📝 Continuous Improvement with User Feedback:

Feedback Collection: Seamlessly gather feedback on any served request, be it on a generation or conversation level.

Weighted Feedback: Obtain nuanced information by attaching weights to user feedback values.

Feedback Metadata: Incorporate custom metadata with the feedback to provide context, allowing for richer insights and analyses.

🔑 Secure Key Management:

Virtual Keys: Portkey transforms original provider keys into virtual keys, ensuring your primary credentials remain untouched.

Multiple Identifiers: Ability to add multiple keys for the same provider or the same key under different names for easy identification without compromising security.
